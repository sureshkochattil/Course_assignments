{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "# settings\n",
    "window_size = 3\n",
    "text_file = \"C:\\\\Users\\\\sures\\\\Downloads\\\\coco_val_sentences.txt\"\n",
    "\n",
    "\n",
    "# functions\n",
    "def preprocessor_word(word):\n",
    "    word = word.lower().strip()\n",
    "    for punc in string.punctuation:\n",
    "        word = word.replace(punc,\"\")\n",
    "    return(word)\n",
    "\n",
    "# main\n",
    "\n",
    "# Initialize\n",
    "word_training_pairs = [] # (target, context) pairs\n",
    "\n",
    "# load text\n",
    "all_sentences = open(text_file).readlines()\n",
    "\n",
    "# extract context\n",
    "\n",
    "for sentence in all_sentences:\n",
    "    sentence_splitted = [preprocessor_word(word) for word in sentence.split()]\n",
    "    for i, target in enumerate(sentence_splitted):\n",
    "        for j in range(1,4):\n",
    "            if not i + j >= len(sentence_splitted):\n",
    "                word_training_pairs.append((target, sentence_splitted[i+j]))\n",
    "            if not i - j < 0:\n",
    "                word_training_pairs.append((target, sentence_splitted[i-j]))\n",
    "\n",
    "\n",
    "#print(word_training_pairs)\n",
    "\n",
    "id2word = list(set([pair[0] for pair in word_training_pairs]))\n",
    "#print(id2word)\n",
    "word2id = {w:i for i, w in enumerate (id2word)}\n",
    "word_training_pairs = [(word2id[pair[0]], word2id[pair[1]]) for pair in word_training_pairs  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18309"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph\n",
    "vocabulary_size = len(id2word)\n",
    "embedding_size = 50\n",
    "batch_size = 100\n",
    "\n",
    "\n",
    "# variables\n",
    "\n",
    "w_embeddings = tf.Variable(tf.random_uniform([vocabulary_size, embedding_size]))\n",
    "softmax_weights =  tf.Variable(tf.random_uniform([embedding_size,vocabulary_size]))\n",
    "\n",
    "# input\n",
    "\n",
    "train_pairs = tf.placeholder(tf.int32, shape = [None,2])\n",
    "train_input = train_pairs[:,0]\n",
    "train_output = train_pairs[:,1]\n",
    "\n",
    "# model\n",
    "\n",
    "w_embd = tf.nn.embedding_lookup(w_embeddings,train_input)\n",
    "prediction = tf.matmul(w_embd, softmax_weights)\n",
    "\n",
    "# loss\n",
    "\n",
    "loss = tf.losses.sparse_softmax_cross_entropy(train_output, prediction)\n",
    "\n",
    "# optimizer\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(0.01).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "loss_hist =[]\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(0, len(word_training_pairs), batch_size):\n",
    "                batch_data = word_training_pairs[i:i+batch_size]\n",
    "                #print(len(batch_data))\n",
    "                _, loss_value = sess.run([optimizer, loss], feed_dict = {train_pairs:batch_data})\n",
    "                loss_hist.append(loss_hist)\n",
    "                   \n",
    "    W = sess.run(w_embeddings)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18309, 50)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.11776736, -0.02214624,  0.25439596, ...,  0.17768185,\n",
       "        -0.94560534,  0.7690013 ],\n",
       "       [ 0.18271548,  0.15488063,  0.19089527, ..., -0.19574301,\n",
       "         0.5605203 ,  1.0901375 ],\n",
       "       [ 0.20374803, -0.03974609, -0.45830786, ...,  0.7548938 ,\n",
       "         0.47588712, -0.02808652],\n",
       "       ...,\n",
       "       [-0.26966155,  0.64500356,  1.0570655 , ...,  0.5889324 ,\n",
       "        -0.30192262,  0.28903794],\n",
       "       [-0.28609926, -0.17132397, -0.10276785, ...,  0.6116154 ,\n",
       "         0.29895425,  0.29451463],\n",
       "       [ 0.31538153,  0.9849304 ,  1.8993207 , ...,  1.1043595 ,\n",
       "         0.13660835,  0.9297342 ]], dtype=float32)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"W_coco_val_newer.npy\", W)\n",
    "#W = np.load(\"W.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"coco_val_newer.txt\",\"w\")\n",
    "for w in id2word:\n",
    "    f.write(w+\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='coco_val_new.txt' mode='w' encoding='cp1252'>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
