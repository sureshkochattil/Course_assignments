{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project\n",
    "# The following procedural of the pipeline were followed:\n",
    "\n",
    "1. Data Loading\n",
    "\n",
    "2. Model Learning\n",
    "\n",
    "3. Model Evaluation\n",
    "\n",
    "# The following logistic regression models have been deployed and the accuracies observed against each are:\n",
    "\n",
    "1. RandomForestClassifier (79%)\n",
    "2. LogisticRegression (81%)\n",
    "3. DecisionTreeClassifier (82)%\n",
    "4. MultilayerPerceptronClassifier (82%)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import findspark \n",
    "import findspark\n",
    "\n",
    "# Or use this alternative\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Build the SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "   .master(\"local\") \\\n",
    "   .appName(\"Project\") \\\n",
    "   .config(\"spark.executor.memory\", \"1gb\") \\\n",
    "   .getOrCreate()\n",
    "   \n",
    "sc = spark.sparkContext\n",
    "#sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext = SQLContext(sc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext = SQLContext(sc)\n",
    "schema = StructType([ \\\n",
    "    StructField(\"ID\", DoubleType(), True), \\\n",
    "    StructField(\"LIMIT_BAL\", DoubleType(), True), \\\n",
    "    StructField(\"SEX\", DoubleType(), True), \\\n",
    "    StructField(\"EDUCATION\",DoubleType() , True), \\\n",
    "    StructField(\"MARRIAGE\",DoubleType() , True), \\\n",
    "    StructField(\"AGE\", DoubleType(), True), \\\n",
    "    StructField(\"PAY_0\", DoubleType(), True), \\\n",
    "    StructField(\"PAY_2\", DoubleType(), True), \\\n",
    "    StructField(\"PAY_3\", DoubleType(), True), \\\n",
    "    StructField(\"PAY_4\", DoubleType(), True), \\\n",
    "    StructField(\"PAY_5\", DoubleType(), True), \\\n",
    "    StructField(\"PAY_6\", DoubleType(), True), \\\n",
    "    StructField(\"BILL_AMT1\", DoubleType(), True), \\\n",
    "    StructField(\"BILL_AMT2\", DoubleType(), True), \\\n",
    "    StructField(\"BILL_AMT3\", DoubleType(), True), \\\n",
    "    StructField(\"BILL_AMT4\", DoubleType(), True), \\\n",
    "    StructField(\"BILL_AMT5\", DoubleType(), True), \\\n",
    "    StructField(\"BILL_AMT6\", DoubleType(), True), \\\n",
    "    StructField(\"PAY_AMT1\", DoubleType(), True), \\\n",
    "    StructField(\"PAY_AMT2\", DoubleType(), True), \\\n",
    "    StructField(\"PAY_AMT3\", DoubleType(), True), \\\n",
    "    StructField(\"PAY_AMT4\", DoubleType(), True), \\\n",
    "    StructField(\"PAY_AMT5\", DoubleType(), True), \\\n",
    "    StructField(\"PAY_AMT6\", DoubleType(), True), \\\n",
    "    StructField(\"default payment next month\", DoubleType(), True)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_data = sqlContext.read \\\n",
    "    .format('com.databricks.spark.csv') \\\n",
    "    .load('C:\\\\Users\\\\sures\\\\Downloads\\\\default_credit_card.csv', schema = schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_data = spark.read.load(\"C:\\\\Users\\\\sures\\\\Downloads\\\\default_credit_card.csv\", header= 'true',format = \"csv\")\n",
    "#default_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(ID=None, LIMIT_BAL=None, SEX=None, EDUCATION=None, MARRIAGE=None, AGE=None, PAY_0=None, PAY_2=None, PAY_3=None, PAY_4=None, PAY_5=None, PAY_6=None, BILL_AMT1=None, BILL_AMT2=None, BILL_AMT3=None, BILL_AMT4=None, BILL_AMT5=None, BILL_AMT6=None, PAY_AMT1=None, PAY_AMT2=None, PAY_AMT3=None, PAY_AMT4=None, PAY_AMT5=None, PAY_AMT6=None, default payment next month=None),\n",
       " Row(ID=1.0, LIMIT_BAL=20000.0, SEX=2.0, EDUCATION=2.0, MARRIAGE=1.0, AGE=24.0, PAY_0=2.0, PAY_2=2.0, PAY_3=-1.0, PAY_4=-1.0, PAY_5=-2.0, PAY_6=-2.0, BILL_AMT1=3913.0, BILL_AMT2=3102.0, BILL_AMT3=689.0, BILL_AMT4=0.0, BILL_AMT5=0.0, BILL_AMT6=0.0, PAY_AMT1=0.0, PAY_AMT2=689.0, PAY_AMT3=0.0, PAY_AMT4=0.0, PAY_AMT5=0.0, PAY_AMT6=0.0, default payment next month=1.0),\n",
       " Row(ID=2.0, LIMIT_BAL=120000.0, SEX=2.0, EDUCATION=2.0, MARRIAGE=2.0, AGE=26.0, PAY_0=-1.0, PAY_2=2.0, PAY_3=0.0, PAY_4=0.0, PAY_5=0.0, PAY_6=2.0, BILL_AMT1=2682.0, BILL_AMT2=1725.0, BILL_AMT3=2682.0, BILL_AMT4=3272.0, BILL_AMT5=3455.0, BILL_AMT6=3261.0, PAY_AMT1=0.0, PAY_AMT2=1000.0, PAY_AMT3=1000.0, PAY_AMT4=1000.0, PAY_AMT5=0.0, PAY_AMT6=2000.0, default payment next month=1.0),\n",
       " Row(ID=3.0, LIMIT_BAL=90000.0, SEX=2.0, EDUCATION=2.0, MARRIAGE=2.0, AGE=34.0, PAY_0=0.0, PAY_2=0.0, PAY_3=0.0, PAY_4=0.0, PAY_5=0.0, PAY_6=0.0, BILL_AMT1=29239.0, BILL_AMT2=14027.0, BILL_AMT3=13559.0, BILL_AMT4=14331.0, BILL_AMT5=14948.0, BILL_AMT6=15549.0, PAY_AMT1=1518.0, PAY_AMT2=1500.0, PAY_AMT3=1000.0, PAY_AMT4=1000.0, PAY_AMT5=1000.0, PAY_AMT6=5000.0, default payment next month=0.0),\n",
       " Row(ID=4.0, LIMIT_BAL=50000.0, SEX=2.0, EDUCATION=2.0, MARRIAGE=1.0, AGE=37.0, PAY_0=0.0, PAY_2=0.0, PAY_3=0.0, PAY_4=0.0, PAY_5=0.0, PAY_6=0.0, BILL_AMT1=46990.0, BILL_AMT2=48233.0, BILL_AMT3=49291.0, BILL_AMT4=28314.0, BILL_AMT5=28959.0, BILL_AMT6=29547.0, PAY_AMT1=2000.0, PAY_AMT2=2019.0, PAY_AMT3=1200.0, PAY_AMT4=1100.0, PAY_AMT5=1069.0, PAY_AMT6=1000.0, default payment next month=0.0)]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#default_data.na.drop()\n",
    "default_data.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train, test) = default_data.randomSplit([0.75, 0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of records in training data are:  22415\n",
      "number of records in test data are:  7589\n"
     ]
    }
   ],
   "source": [
    "print(\"number of records in training data are: \", train.count())\n",
    "print(\"number of records in test data are: \", test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label_indexer = StringIndexer(inputCol = 'churned', outputCol = 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plan_indexer = StringIndexer(inputCol = 'intl_plan', outputCol = 'intl_plan_indexed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [\"LIMIT_BAL\", \"SEX\", \"EDUCATION\",\n",
    "                        \"MARRIAGE\", \"AGE\", \"PAY_0\", \"PAY_2\",\"PAY_3\",\"PAY_4\",\"PAY_5\",\"PAY_6\",\n",
    "                        \"BILL_AMT1\", \"BILL_AMT2\",\"BILL_AMT3\",\"BILL_AMT4\",\"BILL_AMT5\",\"BILL_AMT6\",\n",
    "                        \"PAY_AMT1\", \"PAY_AMT2\",\"PAY_AMT3\",\"PAY_AMT4\",\"PAY_AMT5\",\"PAY_AMT6\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols = numeric_cols,\n",
    "    outputCol = 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.show of DataFrame[ID: double, LIMIT_BAL: double, SEX: double, EDUCATION: double, MARRIAGE: double, AGE: double, PAY_0: double, PAY_2: double, PAY_3: double, PAY_4: double, PAY_5: double, PAY_6: double, BILL_AMT1: double, BILL_AMT2: double, BILL_AMT3: double, BILL_AMT4: double, BILL_AMT5: double, BILL_AMT6: double, PAY_AMT1: double, PAY_AMT2: double, PAY_AMT3: double, PAY_AMT4: double, PAY_AMT5: double, PAY_AMT6: double, default payment next month: double, features: vector]>"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assembler.setHandleInvalid(\"skip\").transform(default_data).show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "# labelCol = Target Variable , featuresCol = Input Variables\n",
    "classifier = RandomForestClassifier(labelCol = 'default payment next month', featuresCol = 'features')\n",
    "\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages=[assembler, classifier])\n",
    "model = pipeline.fit(train)\n",
    "predictions = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[ID: double, LIMIT_BAL: double, SEX: double, EDUCATION: double, MARRIAGE: double, AGE: double, PAY_0: double, PAY_2: double, PAY_3: double, PAY_4: double, PAY_5: double, PAY_6: double, BILL_AMT1: double, BILL_AMT2: double, BILL_AMT3: double, BILL_AMT4: double, BILL_AMT5: double, BILL_AMT6: double, PAY_AMT1: double, PAY_AMT2: double, PAY_AMT3: double, PAY_AMT4: double, PAY_AMT5: double, PAY_AMT6: double, default payment next month: double, features: vector, rawPrediction: vector, probability: vector, prediction: double]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+---+---------+--------------------------+\n",
      "|LIMIT_BAL| AGE|SEX|EDUCATION|default payment next month|\n",
      "+---------+----+---+---------+--------------------------+\n",
      "| 120000.0|26.0|2.0|      2.0|                       1.0|\n",
      "|  70000.0|30.0|1.0|      2.0|                       1.0|\n",
      "|  50000.0|23.0|2.0|      3.0|                       0.0|\n",
      "|  50000.0|47.0|2.0|      3.0|                       0.0|\n",
      "|  10000.0|22.0|1.0|      2.0|                       0.0|\n",
      "+---------+----+---+---------+--------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# now we look at the predictions\n",
    "predictions.select(predictions[\"LIMIT_BAL\"],predictions[\"AGE\"],predictions[\"SEX\"], predictions[\"EDUCATION\"], predictions[\"default payment next month\"]).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the RandomForest model on the test data is:  0.8035711414885208\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"default payment next month\")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"The accuracy of the RandomForest model on the test data is: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+---+---------+--------+----+-----+-----+-----+-----+-----+-----+---------+---------+---------+---------+---------+---------+--------+--------+--------+--------+--------+--------+--------------------------+--------------------+--------------------+--------------------+----------+\n",
      "|  ID|LIMIT_BAL|SEX|EDUCATION|MARRIAGE| AGE|PAY_0|PAY_2|PAY_3|PAY_4|PAY_5|PAY_6|BILL_AMT1|BILL_AMT2|BILL_AMT3|BILL_AMT4|BILL_AMT5|BILL_AMT6|PAY_AMT1|PAY_AMT2|PAY_AMT3|PAY_AMT4|PAY_AMT5|PAY_AMT6|default payment next month|            features|       rawPrediction|         probability|prediction|\n",
      "+----+---------+---+---------+--------+----+-----+-----+-----+-----+-----+-----+---------+---------+---------+---------+---------+---------+--------+--------+--------+--------+--------+--------+--------------------------+--------------------+--------------------+--------------------+----------+\n",
      "| 2.0| 120000.0|2.0|      2.0|     2.0|26.0| -1.0|  2.0|  0.0|  0.0|  0.0|  2.0|   2682.0|   1725.0|   2682.0|   3272.0|   3455.0|   3261.0|     0.0|  1000.0|  1000.0|  1000.0|     0.0|  2000.0|                       1.0|[120000.0,2.0,2.0...|[1.68662912989023...|[0.84378034310996...|       0.0|\n",
      "|14.0|  70000.0|1.0|      2.0|     2.0|30.0|  1.0|  2.0|  2.0|  0.0|  0.0|  2.0|  65802.0|  67369.0|  65701.0|  66782.0|  36137.0|  36894.0|  3200.0|     0.0|  3000.0|  3000.0|  1500.0|     0.0|                       1.0|[70000.0,1.0,2.0,...|[0.37800359390485...|[0.59339150396325...|       0.0|\n",
      "|16.0|  50000.0|2.0|      3.0|     3.0|23.0|  1.0|  2.0|  0.0|  0.0|  0.0|  0.0|  50614.0|  29173.0|  28116.0|  28771.0|  29531.0|  30211.0|     0.0|  1500.0|  1100.0|  1200.0|  1300.0|  1100.0|                       0.0|[50000.0,2.0,3.0,...|[0.72520608860239...|[0.67375240143346...|       0.0|\n",
      "|29.0|  50000.0|2.0|      3.0|     1.0|47.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|    650.0|   3415.0|   3416.0|   2040.0|  30430.0|    257.0|  3415.0|  3421.0|  2044.0| 30430.0|   257.0|     0.0|                       0.0|[50000.0,2.0,3.0,...|[2.03042499188656...|[0.88395468020450...|       0.0|\n",
      "|43.0|  10000.0|1.0|      2.0|     2.0|22.0|  0.0|  0.0|  0.0|  0.0|  0.0|  0.0|   1877.0|   3184.0|   6003.0|   3576.0|   3670.0|   4451.0|  1500.0|  2927.0|  1000.0|   300.0|  1000.0|   500.0|                       0.0|[10000.0,1.0,2.0,...|[1.28885788194473...|[0.78395381111139...|       0.0|\n",
      "+----+---------+---+---------+--------+----+-----+-----+-----+-----+-----+-----+---------+---------+---------+---------+---------+---------+--------+--------+--------+--------+--------+--------+--------------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test set accuracy of Logistic Regression = 0.813545921728818\n"
     ]
    }
   ],
   "source": [
    "#from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "\n",
    "classifier = LogisticRegression(labelCol = 'default payment next month', featuresCol = 'features', maxIter=10)\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages=[assembler, classifier])\n",
    "\n",
    "# train the model\n",
    "model = pipeline.fit(train)\n",
    "\n",
    "# select example rows to display.\n",
    "predictions = model.transform(test)\n",
    "predictions.show(5)\n",
    "\n",
    "# compute accuracy on the test set\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"default payment next month\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy of Logistic Regression = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+---+---------+--------+----+-----+-----+-----+-----+-----+-----+---------+---------+---------+---------+---------+---------+--------+--------+--------+--------+--------+--------+--------------------------+--------------------+----------------+--------------------+----------+\n",
      "|  ID|LIMIT_BAL|SEX|EDUCATION|MARRIAGE| AGE|PAY_0|PAY_2|PAY_3|PAY_4|PAY_5|PAY_6|BILL_AMT1|BILL_AMT2|BILL_AMT3|BILL_AMT4|BILL_AMT5|BILL_AMT6|PAY_AMT1|PAY_AMT2|PAY_AMT3|PAY_AMT4|PAY_AMT5|PAY_AMT6|default payment next month|            features|   rawPrediction|         probability|prediction|\n",
      "+----+---------+---+---------+--------+----+-----+-----+-----+-----+-----+-----+---------+---------+---------+---------+---------+---------+--------+--------+--------+--------+--------+--------+--------------------------+--------------------+----------------+--------------------+----------+\n",
      "| 2.0| 120000.0|2.0|      2.0|     2.0|26.0| -1.0|  2.0|  0.0|  0.0|  0.0|  2.0|   2682.0|   1725.0|   2682.0|   3272.0|   3455.0|   3261.0|     0.0|  1000.0|  1000.0|  1000.0|     0.0|  2000.0|                       1.0|[120000.0,2.0,2.0...|   [535.0,369.0]|[0.59181415929203...|       0.0|\n",
      "|14.0|  70000.0|1.0|      2.0|     2.0|30.0|  1.0|  2.0|  2.0|  0.0|  0.0|  2.0|  65802.0|  67369.0|  65701.0|  66782.0|  36137.0|  36894.0|  3200.0|     0.0|  3000.0|  3000.0|  1500.0|     0.0|                       1.0|[70000.0,1.0,2.0,...|   [535.0,369.0]|[0.59181415929203...|       0.0|\n",
      "|16.0|  50000.0|2.0|      3.0|     3.0|23.0|  1.0|  2.0|  0.0|  0.0|  0.0|  0.0|  50614.0|  29173.0|  28116.0|  28771.0|  29531.0|  30211.0|     0.0|  1500.0|  1100.0|  1200.0|  1300.0|  1100.0|                       0.0|[50000.0,2.0,3.0,...|   [535.0,369.0]|[0.59181415929203...|       0.0|\n",
      "|29.0|  50000.0|2.0|      3.0|     1.0|47.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|    650.0|   3415.0|   3416.0|   2040.0|  30430.0|    257.0|  3415.0|  3421.0|  2044.0| 30430.0|   257.0|     0.0|                       0.0|[50000.0,2.0,3.0,...|[11067.0,1326.0]|[0.89300411522633...|       0.0|\n",
      "|43.0|  10000.0|1.0|      2.0|     2.0|22.0|  0.0|  0.0|  0.0|  0.0|  0.0|  0.0|   1877.0|   3184.0|   6003.0|   3576.0|   3670.0|   4451.0|  1500.0|  2927.0|  1000.0|   300.0|  1000.0|   500.0|                       0.0|[10000.0,1.0,2.0,...|[11067.0,1326.0]|[0.89300411522633...|       0.0|\n",
      "+----+---------+---+---------+--------+----+-----+-----+-----+-----+-----+-----+---------+---------+---------+---------+---------+---------+--------+--------+--------+--------+--------+--------+--------------------------+--------------------+----------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test set accuracy of DecisionTree is = 0.8219791803926736\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "#dt = DecisionTreeClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\")\n",
    "\n",
    "classifier = DecisionTreeClassifier(labelCol = 'default payment next month', featuresCol = 'features')\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages=[assembler, classifier])\n",
    "\n",
    "# train the model\n",
    "model = pipeline.fit(train)\n",
    "\n",
    "# select example rows to display.\n",
    "predictions = model.transform(test)\n",
    "predictions.show(5)\n",
    "\n",
    "# compute accuracy on the test set\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"default payment next month\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy of DecisionTree is = \" + str(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+---+---------+--------+----+-----+-----+-----+-----+-----+-----+---------+---------+---------+---------+---------+---------+--------+--------+--------+--------+--------+--------+--------------------------+--------------------+----------------+--------------------+----------+\n",
      "|  ID|LIMIT_BAL|SEX|EDUCATION|MARRIAGE| AGE|PAY_0|PAY_2|PAY_3|PAY_4|PAY_5|PAY_6|BILL_AMT1|BILL_AMT2|BILL_AMT3|BILL_AMT4|BILL_AMT5|BILL_AMT6|PAY_AMT1|PAY_AMT2|PAY_AMT3|PAY_AMT4|PAY_AMT5|PAY_AMT6|default payment next month|            features|   rawPrediction|         probability|prediction|\n",
      "+----+---------+---+---------+--------+----+-----+-----+-----+-----+-----+-----+---------+---------+---------+---------+---------+---------+--------+--------+--------+--------+--------+--------+--------------------------+--------------------+----------------+--------------------+----------+\n",
      "| 2.0| 120000.0|2.0|      2.0|     2.0|26.0| -1.0|  2.0|  0.0|  0.0|  0.0|  2.0|   2682.0|   1725.0|   2682.0|   3272.0|   3455.0|   3261.0|     0.0|  1000.0|  1000.0|  1000.0|     0.0|  2000.0|                       1.0|[120000.0,2.0,2.0...|   [535.0,369.0]|[0.59181415929203...|       0.0|\n",
      "|14.0|  70000.0|1.0|      2.0|     2.0|30.0|  1.0|  2.0|  2.0|  0.0|  0.0|  2.0|  65802.0|  67369.0|  65701.0|  66782.0|  36137.0|  36894.0|  3200.0|     0.0|  3000.0|  3000.0|  1500.0|     0.0|                       1.0|[70000.0,1.0,2.0,...|   [535.0,369.0]|[0.59181415929203...|       0.0|\n",
      "|16.0|  50000.0|2.0|      3.0|     3.0|23.0|  1.0|  2.0|  0.0|  0.0|  0.0|  0.0|  50614.0|  29173.0|  28116.0|  28771.0|  29531.0|  30211.0|     0.0|  1500.0|  1100.0|  1200.0|  1300.0|  1100.0|                       0.0|[50000.0,2.0,3.0,...|   [535.0,369.0]|[0.59181415929203...|       0.0|\n",
      "|29.0|  50000.0|2.0|      3.0|     1.0|47.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|    650.0|   3415.0|   3416.0|   2040.0|  30430.0|    257.0|  3415.0|  3421.0|  2044.0| 30430.0|   257.0|     0.0|                       0.0|[50000.0,2.0,3.0,...|[11067.0,1326.0]|[0.89300411522633...|       0.0|\n",
      "|43.0|  10000.0|1.0|      2.0|     2.0|22.0|  0.0|  0.0|  0.0|  0.0|  0.0|  0.0|   1877.0|   3184.0|   6003.0|   3576.0|   3670.0|   4451.0|  1500.0|  2927.0|  1000.0|   300.0|  1000.0|   500.0|                       0.0|[10000.0,1.0,2.0,...|[11067.0,1326.0]|[0.89300411522633...|       0.0|\n",
      "+----+---------+---+---------+--------+----+-----+-----+-----+-----+-----+-----+---------+---------+---------+---------+---------+---------+--------+--------+--------+--------+--------+--------+--------------------------+--------------------+----------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test set accuracy pf Perceptron is = 0.8219791803926736\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "#specify layers for the neural network:\n",
    "# input layer of size 4 (features), two intermediate of size 5 and 4\n",
    "# and output of size 3 (classes)\n",
    "layers = [4, 5, 4, 3]\n",
    "\n",
    "# create the trainer and set its parameters\n",
    "classifier = MultilayerPerceptronClassifier(labelCol = 'default payment next month', featuresCol = 'features', maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "#trainer = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "\n",
    "# train the model\n",
    "model = pipeline.fit(train)\n",
    "\n",
    "# compute accuracy on the test set\n",
    "result = model.transform(test)\n",
    "predictionAndLabels = result.select(\"prediction\", \"default payment next month\")\n",
    "predictions.show(5)\n",
    "#evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"default payment next month\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "print(\"Test set accuracy pf Perceptron is = \" + str(evaluator.evaluate(predictionAndLabels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
